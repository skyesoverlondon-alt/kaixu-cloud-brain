version: '3.8'

services:
  kaixu-brain:
    image: vllm/vllm-openai:latest
    container_name: kaixu-brain-v1
    runtime: nvidia
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - CUDA_VISIBLE_DEVICES=0
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
      - ./logs:/logs
    command: >
      --model meta-llama/Llama-3.1-8B-Instruct
      --port 8000
      --host 0.0.0.0
      --api-key ${API_KEY:-kaixu-internal-key}
      --served-model-name kaixu-brain-v1
      --max-model-len 8192
      --gpu-memory-utilization 0.9
      --enforce-eager
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  kaixu-orchestrator:
    build: .
    container_name: kaixu-orchestrator
    ports:
      - "8080:8080"
    environment:
      - KAIXU_BRAIN_URL=http://kaixu-brain:8000
      - KAIXU_BRAIN_API_KEY=${API_KEY:-kaixu-internal-key}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ORCHESTRATOR_PORT=8080
    volumes:
      - ./orchestrator_logs:/app/logs
    depends_on:
      - kaixu-brain
    restart: unless-stopped

  nginx-proxy:
    image: nginx:alpine
    container_name: kaixu-proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - kaixu-orchestrator
    restart: unless-stopped

volumes:
  redis_data:
